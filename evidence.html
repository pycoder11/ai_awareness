<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Evidence â€” AI in IT Companies</title>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  <main>
    <nav>
      <a href="essay.html">Essay</a>
      <a href="evidence.html">Evidence</a>
      <a href="survey.html">Survey & Interviews</a>
    </nav>

    <h1>Evidence supporting the argument</h1>

    <div class="subchunk">
      Multiple studies and industry reports back the main points: research shows AI tools can speed routine engineering tasks but may also produce insecure or incorrect code unless humans check outputs; government and research groups warn of security and reliability risks for AI-generated code and recommend formal risk management steps for teams.
    </div>

    <div class="subchunk">
      For example, work from policy researchers and cybersecurity teams documents how AI code generation can introduce vulnerabilities and supply insecure patterns, while major developer-tool vendors report both productivity gains and the need for review; likewise, technical analyses explain why large language models sometimes invent facts or plausible-looking but false outputs, which means teams must verify important claims.
    </div>

    <div class="subchunk">
      Taken together, these findings show that AI offers clear efficiency benefits while also posing real risks that organizations must manage with policies, audits, and human oversight.
    </div>
  </main>
</body>
</html>
