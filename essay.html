<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Essay — AI in IT Companies</title>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  <main>
    <nav>
      <a href="essay.html">Essay</a>
      <a href="evidence.html">Evidence</a>
      <a href="survey.html">Survey & Interviews</a>
    </nav>

    <h1>Is artificial intelligence helping or hurting IT companies?</h1>

    <div class="subchunk">
      Artificial intelligence has quickly become a regular tool inside IT teams, used to speed up coding, write documentation, and automate testing and routine tasks; while this helps with short term productivity, I argue that unchecked AI use can weaken critical technical skills and reduce accountability unless teams adopt clear rules and human review.
    </div>

    <div class="subchunk">
      The history matters: tools such as GitHub Copilot, OpenAI’s code models, and similar products from large cloud vendors have pushed AI into developer workflows, and many companies now rely on these assistants for boilerplate code and suggestions. This shift makes it more likely that junior staff will accept AI outputs without deep vetting, and that subtle errors will be copied into production systems.
    </div>

    <div class="subchunk">
      In fields like security, data engineering, and systems design, those errors can cause real harm. To keep the benefits while limiting the risks, IT teams should adopt lightweight policies, require human checks for critical changes, train staff on how the models work, and log AI use so teams can audit and learn from mistakes.
    </div>
  </main>
</body>
</html>
